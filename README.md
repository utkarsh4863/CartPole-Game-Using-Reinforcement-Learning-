# ğŸš€ CartPole Game Using Reinforcement Learning

This project showcases and compares several Reinforcement Learning (RL) algorithms using the classic **CartPole-v1** environment from [OpenAI Gymnasium](https://gymnasium.farama.org/). Train, evaluate, and visualize agents easily within a Jupyter Notebook or interactively with a **Streamlit app** for real-time gameplay.

---

## ğŸ§© Key Features

- **Implemented Agents**
  - ğŸ”¹ Random Policy  
  - ğŸ”¹ SARSA (Tabular)  
  - ğŸ”¹ REINFORCE (Policy Gradient)  
  - ğŸ”¹ DQN (Deep Q-Network)  

- **Streamlit App**  
  - Real-time gameplay
  - Live reward statistics & visualizations  

- **Jupyter Notebook**  
  - Train & evaluate agents step-by-step  
  - Save/load trained models easily  

- **Pre-trained Models**  
  - No need to retrain agents every time  
  - Models ready for use in `models/` folder  

---

## ğŸ¯ Objective

Interactive visual playground for **comparing RL agents**, understanding their strengths, and learning reinforcement learning by doing.

---

## ğŸŒ Live Demo

ğŸ‰ **See it in action on Streamlit:**  
[Open the CartPole RL Game live!](https://mvxe7kkcg2fpyiuwpfmpkf.streamlit.app/)

---

## ğŸ§  Tech Stack

| Category          | Tools                                 |
|-------------------|---------------------------------------|
| **Language**      | Python ğŸ                             |
| **Frameworks**    | Gymnasium, Streamlit, PyTorch         |
| **Libraries**     | numpy, matplotlib                     |
| **Visualization** | Streamlit, Matplotlib                 |
| **Environment**   | OpenAI Gymnasium CartPole-v1          |

---

## âš™ï¸ Installation & Setup (Windows)

1. **Clone the repository**
    ```bash
    git clone https://github.com/utkarsh4863/CartPole-Game-Using-Reinforcement-Learning-.git
    cd "CartPole game project using RL"
    ```

2. **Create a virtual environment**
    ```bash
    python -m venv venv
    ```

3. **Activate the virtual environment**
    ```bash
    venv\Scripts\activate
    ```

4. **Install dependencies**
    ```bash
    pip install -r requirements.txt
    ```

5. **Run the Jupyter Notebook for training & evaluation**
    ```bash
    jupyter notebook "CartPole game using  RL.ipynb"
    ```

6. **Or launch the Streamlit app for gameplay visualization**
    ```bash
    streamlit run streamlit_app.py
    ```

---

## ğŸ““ How To Use (Windows)

### 1. Jupyter Notebook

- Train SARSA / REINFORCE / DQN agents
- Compare performance and visualize reward curves
- Save trained models to `models/`

    ```bash
    jupyter notebook "CartPole game using  RL.ipynb"
    ```

### 2. Streamlit App

- Select agent: Random, SARSA, REINFORCE, DQN
- Set episodes and adjust FPS for smoother gameplay
- Click 'Run' to start simulation
- See live rewards and dynamic reward bar chart

    ```bash
    streamlit run streamlit_app.py
    ```

---

## ğŸ“ Folder Structure

```
CartPole game project using RL/
â”‚â”€â”€ CartPole game using  RL.ipynb
â”‚â”€â”€ streamlit_app.py
â”‚â”€â”€ models/
â”‚     â”œâ”€â”€ sarsa_Q.npy
â”‚     â”œâ”€â”€ reinforce_policy.pth
â”‚     â””â”€â”€ dqn_net.pth
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ .gitignore
â”‚â”€â”€ README.md
```

---

## âš¡ Notes

- The `models/` directory includes pre-trained agents ready for use in Streamlit.
- If you wish to retrain agents, run the notebook and overwrite/save models in the same folder.
- If models are absent, Streamlit runs agents with random policy by default.

---

## ğŸ¤ Author

Developed & maintained by **Utkarsh Kashyap**  
Feel free to connect and contribute! ğŸš€

---
